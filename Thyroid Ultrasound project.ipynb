{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0672f8",
   "metadata": {},
   "source": [
    "### This is a project analyzing the OneFlorida data. With the cohort of the patients who get a Thyroid ultrasound done from 2015 to 2022. \n",
    "\n",
    "The main part include:\n",
    "\n",
    "1.Report the counts for the cohorts + 7.Descriptive analysis for the cohort (Exploratory Data Analysis)\n",
    "\n",
    "2.Define the outcome variables in the regression and logistic model\n",
    "\n",
    "3.Calculte the derivative predictors, like Geocoded social determinants of health (SVI), Charlson comorbidity index etc.\n",
    "\n",
    "4.Conduct the Time to event analysis\n",
    "\n",
    "5.Build the logistic model\n",
    "\n",
    "6.Build the Linear regression model \n",
    "\n",
    "The outcomes are presented into tables and graphs, and are reported in word documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Demographic = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Raw_data/demographic_ospina_v2a.csv') \n",
    "# Procedures = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Raw_data/procedures_ospina_v2a.csv') \n",
    "# Diagnosis = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Raw_data/diagnosis_ospina_v2a.csv') \n",
    "# Encounter = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Raw_data/encounter_ospina_v2a.csv') \n",
    "# Vital = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Raw_data/vital_ospina_v2a.csv')\n",
    "# Condition = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Raw_data/condition_ospina_v2a.csv') \n",
    "# address_history = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Raw_data/address_history_ospina_v2a.csv') \n",
    "# Denominator = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Adjusted.csv', dtype={'RACE': str}) \n",
    "\n",
    "# first_diag = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/first_diag.csv')\n",
    "Demographic6 = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Demographic6.csv')\n",
    "Demographic6_18month = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Demographic6_18month.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-speed",
   "metadata": {},
   "source": [
    "# 1.Report the counts for cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-tourist",
   "metadata": {},
   "source": [
    "## A. Adult patients with first thyroid ultrasound + Thyroid Nodule Diagnosis 2015-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the year of biopsy\n",
    "Procedures['PX_YEAR'] = Procedures['PX_DATE'].str[-4:]\n",
    "# Filter the DataFrame based on biopsy CPT\n",
    "filtered_Procedures = Procedures[Procedures['PX'] == '76536']\n",
    "\n",
    "# Get the index date - fisrt ultrasound\n",
    "# Based on PxDATE, if there are missing in PX date use admit date. \n",
    "filtered_Procedures['DATE'] = filtered_Procedures['PX_DATE'].fillna(filtered_Procedures['ADMIT_DATE'])\n",
    "# Convert the 'Date' column to datetime type\n",
    "filtered_Procedures['DATE'] = pd.to_datetime(filtered_Procedures['DATE'])\n",
    "filtered_Procedures = filtered_Procedures[filtered_Procedures['DATE']>='2015-01-01 00:00:00']\n",
    "print(len(filtered_Procedures['ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All patient in data\n",
    "print(len(Procedures['ID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-wesley",
   "metadata": {},
   "source": [
    "## B. Patients with thyroid biopsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame based on biopsy CPT\n",
    "filtered_Procedures1 = Procedures[Procedures['PX'] .isin(['60100','10022','10005','10006','10004','10021','60001','60300','76942'])]\n",
    "\n",
    "# Based on PxDATE, if there are missing in PX date use admit date. \n",
    "filtered_Procedures1['DATE'] = filtered_Procedures1['PX_DATE'].fillna(filtered_Procedures1['ADMIT_DATE'])\n",
    "# Convert the 'Date' column to datetime type\n",
    "filtered_Procedures1['DATE'] = pd.to_datetime(filtered_Procedures1['DATE'])\n",
    "filtered_Procedures1 = filtered_Procedures1[filtered_Procedures1['DATE']>='2015-01-01 00:00:00']\n",
    "\n",
    "Biopsy_ID = filtered_Procedures1['ID'].unique()\n",
    "print(len(Biopsy_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first date for each ID\n",
    "first_dates1 = filtered_Procedures1.groupby('ID')['DATE'].min()\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "result_df1 = pd.DataFrame({'ID': first_dates1.index, 'First_Date': first_dates1.values})\n",
    "result_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-person",
   "metadata": {},
   "source": [
    "## C. Patients with Thyroid Cancer diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#US_Nodule_ID = US_Nodule['ID'].unique()\n",
    "US_Nodule_all =  Diagnosis[Diagnosis['ID'] .isin(Biopsy_ID)]\n",
    "\n",
    "#Thyroid cancer diagnosis: 193 and C73\n",
    "Thyroid_cancer = US_Nodule_all[US_Nodule_all['DX'] .isin(['193','C73','C739'])]\n",
    "Thyroid_cancer_ID = Thyroid_cancer['ID'].unique()\n",
    "print(len(Thyroid_cancer_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index date - fisrt biopsy\n",
    "# Based on PxDATE, if there are missing in PX date use admit date. \n",
    "Thyroid_cancer['DATE'] = Thyroid_cancer['DX_DATE'].fillna(Thyroid_cancer['ADMIT_DATE'])\n",
    "\n",
    "# Convert the 'Date' column to datetime type\n",
    "Thyroid_cancer['DATE'] = pd.to_datetime(Thyroid_cancer['DATE'])\n",
    "\n",
    "# Select the first date for each ID\n",
    "first_dates2 = Thyroid_cancer.groupby('ID')['DATE'].min()\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "result_df2 = pd.DataFrame({'ID': first_dates2.index, 'First_Date': first_dates2.values})\n",
    "result_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-period",
   "metadata": {},
   "source": [
    "# 2.Outcome variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-invite",
   "metadata": {},
   "source": [
    "## First date of diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first date for each ID\n",
    "first_dates = filtered_Procedures.groupby('ID')['DATE'].min()\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "result_df = pd.DataFrame({'ID': first_dates.index, 'First_Date': first_dates.values})\n",
    "\n",
    "first_diag = pd.merge(result_df,Demographic, on = 'ID',how = 'left') #Outer join? Because now all the differ date is 0 days\n",
    "conditions = [\n",
    "    first_diag['age']>=65,\n",
    "    first_diag['age']<=39,\n",
    "    first_diag['age'].isin(range(39,65)),\n",
    "]\n",
    "choices = ['>=65', '18-39','40-64']\n",
    "\n",
    "first_diag['age_group'] = np.select(conditions, choices, default='Other')\n",
    "first_diag['PX_YEAR'] = first_diag['First_Date'].dt.year\n",
    "\n",
    "# Create a function to map the year and month to half-year intervals\n",
    "def get_half_year(year, month):\n",
    "    half_year = 'H1' if month <= 6 else 'H2'\n",
    "    return f\"{year}{half_year}\"\n",
    "\n",
    "# Apply the function to the 'DX_YEAR' column\n",
    "first_diag['PX_YEAR_half'] = first_diag.apply(lambda row: get_half_year(row['PX_YEAR'], row['First_Date'].month), axis=1)\n",
    "\n",
    "#Re-categorize variable\n",
    "#Race\n",
    "conditions = [\n",
    "    first_diag['RACE'].isin(['01','04','OT']),\n",
    "    first_diag['RACE'].isin(['07','NI','UN']),\n",
    "    first_diag['RACE'].isin(['02']),\n",
    "    first_diag['RACE'].isin(['03']),\n",
    "    first_diag['RACE'].isin(['05']),\n",
    "    first_diag['RACE'].isin(['06']),\n",
    "]\n",
    "choices = ['Other', 'Unknown','Asian','Black or African American','White','Multiple race']\n",
    "\n",
    "first_diag['RACE1'] = np.select(conditions, choices, default='Other')\n",
    "\n",
    "#first_diag.to_csv('first_diag.csv')\n",
    "first_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "\n",
    "#Import number of adult in OneFlorida by encounter year\n",
    "Total_adult = pd.read_excel('/data2/datasets/Xingke/Thyroid_Biopsy/adult_by_year.xlsx')\n",
    "#The number of adults who had their first thyroid Ultrasound in a given year\n",
    "unique_counts_Ultrasound = first_diag.groupby('PX_YEAR')['ID'].nunique()\n",
    "unique_counts_Ultrasound = unique_counts_Ultrasound.reset_index()\n",
    "#The rate of Ultrasound from 2015 to 2022\n",
    "unique_counts_Ultrasound.rename(columns={'ID': 'Ultrasound_count'}, inplace=True)\n",
    "#unique_counts_Ultrasound = unique_counts_Ultrasound[1:].reset_index(drop=True)\n",
    "unique_counts_Ultrasound['Rate'] = unique_counts_Ultrasound['Ultrasound_count']/ Total_adult['patient_count']\n",
    "unique_counts_Ultrasound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-examination",
   "metadata": {},
   "source": [
    "## Sequetial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biopsy after ultrasound\n",
    "#Index year: Ultrasound\n",
    "biopsy_after = pd.merge(first_diag,first_dates1 , on = 'ID',how = 'left') #merge ultrasound date with biopsy date\n",
    "biopsy_after['First_Date'] = pd.to_datetime(biopsy_after['First_Date']) #ultrasound date\n",
    "biopsy_after['DATE'] = pd.to_datetime(biopsy_after['DATE']) #biopsy date\n",
    "biopsy_after['differ'] = biopsy_after['DATE']-biopsy_after['First_Date']\n",
    "biopsy_afterpatient = biopsy_after[biopsy_after['differ']>='0 days']\n",
    "biopsy_afterpatient['Ultrasound_YEAR'] = biopsy_afterpatient['First_Date'].dt.year\n",
    "biopsy_afterpatient = biopsy_afterpatient.rename(columns={'DATE': 'Biopsy date'})\n",
    "print(len(biopsy_afterpatient))\n",
    "unique_counts_biopsy2 = biopsy_afterpatient.groupby('Ultrasound_YEAR')['ID'].nunique()\n",
    "unique_counts_biopsy2 = unique_counts_biopsy2.reset_index()\n",
    "#unique_counts_biopsy2 =unique_counts_biopsy2[1:].reset_index(drop=True)\n",
    "unique_counts_biopsy2['Rate'] = unique_counts_biopsy2['ID']/unique_counts_Ultrasound['Ultrasound_count']\n",
    "unique_counts_biopsy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biopsy after ultrasound\n",
    "#Index year: biopsy\n",
    "biopsy_after = pd.merge(first_diag,first_dates1 , on = 'ID',how = 'left') #merge ultrasound date with biopsy date\n",
    "biopsy_after['First_Date'] = pd.to_datetime(biopsy_after['First_Date']) #ultrasound date\n",
    "biopsy_after['DATE'] = pd.to_datetime(biopsy_after['DATE']) #biopsy date\n",
    "biopsy_after['differ'] = biopsy_after['DATE']-biopsy_after['First_Date']\n",
    "biopsy_afterpatient = biopsy_after[biopsy_after['differ']>='0 days']\n",
    "biopsy_afterpatient['Biopsy_YEAR'] = biopsy_afterpatient['DATE'].dt.year\n",
    "biopsy_afterpatient = biopsy_afterpatient.rename(columns={'DATE': 'Biopsy date'})\n",
    "print(len(biopsy_afterpatient))\n",
    "unique_counts_biopsy2 = biopsy_afterpatient.groupby('Biopsy_YEAR')['ID'].nunique()\n",
    "unique_counts_biopsy2 = unique_counts_biopsy2.reset_index()\n",
    "#unique_counts_biopsy2 =unique_counts_biopsy2[1:].reset_index(drop=True)\n",
    "unique_counts_biopsy2['Rate'] = unique_counts_biopsy2['ID']/unique_counts_Ultrasound['Ultrasound_count']\n",
    "unique_counts_biopsy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancer after biopsy\n",
    "#Index year: biopsy\n",
    "cancerafter = pd.merge(first_dates2,biopsy_afterpatient, on = 'ID',how = 'left')\n",
    "cancerafter = cancerafter.rename(columns={'DATE': 'Cancer date'})\n",
    "cancerafter['Cancer date'] = pd.to_datetime(cancerafter['Cancer date'])\n",
    "cancerafter['Biopsy date'] = pd.to_datetime(cancerafter['Biopsy date'])\n",
    "cancerafter['differ'] = cancerafter['Biopsy date']-cancerafter['Cancer date']\n",
    "cancerafterpatient = cancerafter[cancerafter['differ']<='0 days']\n",
    "cancerafterpatient['Biopsy_YEAR'] = cancerafterpatient['Biopsy date'].dt.year\n",
    "print(len(cancerafterpatient))\n",
    "unique_counts_cancer2 = cancerafterpatient.groupby('Biopsy_YEAR')['ID'].nunique()\n",
    "unique_counts_cancer2 = unique_counts_cancer2.reset_index()\n",
    "#unique_counts_cancer2['Rate'] = unique_counts_cancer2['ID']/unique_counts_biopsy['Biopsy_count']\n",
    "unique_counts_cancer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancer after biopsy\n",
    "#Index year: cancer\n",
    "cancerafter = pd.merge(first_dates2,biopsy_afterpatient, on = 'ID',how = 'left')\n",
    "cancerafter = cancerafter.rename(columns={'DATE': 'Cancer date'})\n",
    "cancerafter['Cancer date'] = pd.to_datetime(cancerafter['Cancer date'])\n",
    "cancerafter['Biopsy date'] = pd.to_datetime(cancerafter['Biopsy date'])\n",
    "cancerafter['differ'] = cancerafter['Biopsy date']-cancerafter['Cancer date']\n",
    "cancerafterpatient = cancerafter[cancerafter['differ']<='0 days']\n",
    "cancerafterpatient['Cancer_YEAR'] = cancerafterpatient['Cancer date'].dt.year\n",
    "print(len(cancerafterpatient))\n",
    "unique_counts_cancer2 = cancerafterpatient.groupby('Cancer_YEAR')['ID'].nunique()\n",
    "unique_counts_cancer2 = unique_counts_cancer2.reset_index()\n",
    "#unique_counts_cancer2['Rate'] = unique_counts_cancer2['ID']/unique_counts_biopsy['Biopsy_count']\n",
    "unique_counts_cancer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "biopsy_afterID = biopsy_afterpatient['ID'].unique()\n",
    "cancer_afterID = cancerafterpatient['ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After runing the model\n",
    "Biopsy_18month = Demographic6_18month[Demographic6_18month['Biopsy_18month']  == 1]\n",
    "Biopsy_18monthID = Biopsy_18month['ID'].unique()\n",
    "Biopsy_18monthpt = biopsy_afterpatient[biopsy_afterpatient['ID'].isin(Biopsy_18monthID)]\n",
    "\n",
    "Biopsy_18monthpt['Ultrasound_YEAR'] = Biopsy_18monthpt['First_Date'].dt.year\n",
    "Biopsy_18monthpt = Biopsy_18monthpt.rename(columns={'DATE': 'Biopsy date'})\n",
    "unique_counts_biopsy3 = Biopsy_18monthpt.groupby('Ultrasound_YEAR')['ID'].nunique()\n",
    "unique_counts_biopsy3 = unique_counts_biopsy3.reset_index()\n",
    "#unique_counts_biopsy3 =unique_counts_biopsy3[1:].reset_index(drop=True)\n",
    "unique_counts_biopsy3['Rate'] = unique_counts_biopsy3['ID']/unique_counts_Ultrasound['Ultrasound_count']\n",
    "unique_counts_biopsy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After runing the model\n",
    "Biopsy_18month = Demographic6_18month1[Demographic6_18month1['Cancer_18month']  == 1]\n",
    "Biopsy_18monthID = Biopsy_18month['ID'].unique()\n",
    "Biopsy_18monthpt = biopsy_afterpatient[biopsy_afterpatient['ID'].isin(Biopsy_18monthID)]\n",
    "\n",
    "Biopsy_18monthpt['Biopsy_YEAR'] = Biopsy_18monthpt['Biopsy date'].dt.year\n",
    "Biopsy_18monthpt = Biopsy_18monthpt.rename(columns={'DATE': 'Biopsy date'})\n",
    "unique_counts_cancer3 = Biopsy_18monthpt.groupby('Biopsy_YEAR')['ID'].nunique()\n",
    "unique_counts_cancer3 = unique_counts_cancer3.reset_index()\n",
    "#unique_counts_cancer3 =unique_counts_cancer3[1:].reset_index(drop=True)\n",
    "unique_counts_cancer3['Rate'] = unique_counts_cancer3['ID']/unique_counts_Ultrasound['Ultrasound_count']\n",
    "unique_counts_cancer3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-power",
   "metadata": {},
   "source": [
    "# 3.Variables of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-cooperative",
   "metadata": {},
   "source": [
    "## Geocoded social determinants of health (SVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Rurality of each zip code\n",
    "RUCA = pd.read_excel('RUCA2010zipcode.xlsx', sheet_name=1,dtype={0:float}) \n",
    "Rurality =  pd.merge(Encounter, RUCA, left_on = 'FACILITY_LOCATION', right_on = 'ZIP_CODE',how = 'left')\n",
    "Rurality = Rurality.drop(columns=['ZIP_CODE','STATE','ZIP_TYPE'])\n",
    "\n",
    "#Get the SVI of each county\n",
    "SVI = pd.read_csv('SVI_2020_US_county.csv') \n",
    "#Convert county to zipcode\n",
    "COUNTY_ZIP = pd.read_excel('ZIP_COUNTY_032023.xlsx')\n",
    "SVI2 = pd.merge(SVI,COUNTY_ZIP,left_on = 'STCNTY',right_on = 'COUNTY',how = 'left')\n",
    "SVI3 = SVI2[['ZIP','RPL_THEMES']].drop_duplicates(subset='ZIP', keep='first')\n",
    "\n",
    "#Merge Rurality and SVI\n",
    "Rurality_SVI = pd.merge(Rurality, SVI3, left_on = 'FACILITY_LOCATION', right_on = 'ZIP',how = 'left')\n",
    "Rurality_SVI = Rurality_SVI.drop(columns=['ZIP'])\n",
    "\n",
    "filtered_Procedures_new = filtered_Procedures[['ID', 'ENCOUNTERID','ADMIT_DATE','PX_DATE', 'PX' ]]\n",
    "SVI1 = pd.merge(Rurality_SVI, filtered_Procedures_new, on = 'ENCOUNTERID',how = 'left')\n",
    "SVI2 = SVI1[SVI1['PX'] == '76536' ]\n",
    "SVI2.rename(columns={'ID_x': 'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Personal zip code\n",
    "Personzip =  pd.merge(address_history, RUCA, left_on = 'ADDRESS_ZIP5', right_on = 'ZIP_CODE',how = 'left')\n",
    "Personzip = Personzip.drop(columns=['ZIP_CODE','STATE','ZIP_TYPE'])\n",
    "Personzip = pd.merge(Personzip, SVI3, left_on = 'ADDRESS_ZIP5', right_on = 'ZIP',how = 'left')\n",
    "Personzip = Personzip.drop(columns=['ZIP'])\n",
    "Personzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-swing",
   "metadata": {},
   "source": [
    "## Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lambda function to assign values based on conditions in column PAYER_TYPE_PRIMARY\n",
    "def assign_value(row):\n",
    "    row = str(row['PAYER_TYPE_PRIMARY'])\n",
    "    if row.startswith('1'):\n",
    "        return 'MEDICARE'\n",
    "    elif row.startswith('2'):\n",
    "        return 'MEDICAID'\n",
    "    elif row.startswith('3') or row.startswith('4'):\n",
    "        return 'OtherGOV'\n",
    "    elif row.startswith('5') or row.startswith('6'):\n",
    "        return 'PRIVATE'\n",
    "    elif row.startswith('8'):\n",
    "        return 'NOPAY'\n",
    "    elif row.startswith('7') or row.startswith('9') and row != '9999':\n",
    "        return 'Other'\n",
    "    elif row == 'OT':\n",
    "        return 'Other'\n",
    "    elif row == '9999':\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Apply the lambda function to assign values in column B\n",
    "SVI2['Insurance'] = SVI2.apply(assign_value, axis=1)\n",
    "\n",
    "SVI2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For facility zip\n",
    "#Merge with first date of biopsy \n",
    "Encounter1 = pd.merge(result_df,SVI2,on = 'ID',how = 'left')\n",
    "Encounter1['ADMIT_DATE_x'] = pd.to_datetime(Encounter1['ADMIT_DATE_x'])\n",
    "\n",
    "#Find the Encounter date of the most recent date\n",
    "Encounter1['differ'] = Encounter1['ADMIT_DATE_x'] - Encounter1['First_Date']\n",
    "#Encounter1['differ2'] = Encounter1['differ'].abs()\n",
    "#Encounter2 =  Encounter1.groupby('ID')['differ'].min().reset_index().merge(Encounter1, on=['ID', 'differ2'])\n",
    "\n",
    "# Perform the groupby operation to get the minimum value for each ID\n",
    "min_values = Encounter1.groupby('ID')['differ'].min().reset_index()\n",
    "Encounter2 = min_values.merge(Encounter1, on=['ID', 'differ'], how='inner')\n",
    "Encounter22 = Encounter2[Encounter2['differ']>='-180 days +21:00:00']\n",
    "\n",
    "#right join???\n",
    "Encounter3 = Encounter22[['ID','Insurance']].drop_duplicates(subset='ID',keep='first')\n",
    "print(len(Encounter3 ['ID'].unique()))\n",
    "\n",
    "Encounter4 = Encounter22[['ID','RUCA1','RUCA2','FACILITY_LOCATION']].drop_duplicates(subset='ID', keep='first')\n",
    "print(len(Encounter4 ['ID'].unique()))\n",
    "\n",
    "Encounter6 = Encounter22[['ID','RPL_THEMES']].drop_duplicates(subset='ID', keep='first')\n",
    "print(len(Encounter6 ['ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For personal zip\n",
    "#Merge with first date of biopsy \n",
    "Personzip1 = pd.merge(result_df,Personzip,on = 'ID',how = 'left')\n",
    "Personzip1['ADDRESS_PERIOD_START'] = pd.to_datetime(Personzip1['ADDRESS_PERIOD_START'])\n",
    "\n",
    "#Find the Encounter date of the most recent date\n",
    "Personzip1['differ'] = Personzip1['ADDRESS_PERIOD_START'] - Personzip1['First_Date']\n",
    "Personzip1['differ2'] = Personzip1['differ'].abs()\n",
    "Personzip2 =  Personzip1.groupby('ID')['differ2'].min().reset_index().merge(Personzip1, on=['ID', 'differ2'])\n",
    "\n",
    "#right join???\n",
    "Personzip3 = Personzip2[['ID','RPL_THEMES','ADDRESS_ZIP5']].drop_duplicates(subset='ID',keep='first')\n",
    "print(len(Personzip3 ['ID'].unique()))\n",
    "\n",
    "Personzip4 = Personzip2[['ID','RUCA1']].drop_duplicates(subset='ID',keep='first')\n",
    "print(len(Personzip4 ['ID'].unique()))\n",
    "\n",
    "Personzip4.rename(columns={'RUCA1': 'RUCA1_Person'}, inplace=True)\n",
    "Personzip3.rename(columns={'RPL_THEMES': 'SVI_Person'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-diabetes",
   "metadata": {},
   "source": [
    "## Charlson comorbidity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used Packages from Shuang to calculate CCI index\n",
    "Commoridity = pd.read_csv('commoridity.csv')\n",
    "Commoridity['CCI'] = Commoridity['AIDS']*6 + Commoridity['Any malignancy,includes leukemia and lympyoma']*2 +Commoridity['Cerebrovascular Disease']*1 +Commoridity['Chronic Pulmonary Disease']*1 +Commoridity['Congestive Heart Failure']*1 +Commoridity['Dementia']*1 +Commoridity['Diabetes']*1 +Commoridity['Diabetes with Chronic Complications']*2 +Commoridity['Hemiplegia or Paraplegia']*2 +Commoridity['Metastaic solid tumor']*6 +Commoridity['Mild Liver Disease']*1 +Commoridity['Moderate or Severe Liver Disease']*3 +Commoridity['Myocardial Infarction']*1 +Commoridity['Peptic Ulcer Disease']*1+Commoridity['Peripheral Vascular Disease']*1+Commoridity['Renal Disease']*2 +Commoridity['Rheumatologic Disease']*1\n",
    "first_diag = pd.merge(first_diag,Commoridity,left_on = 'ID',right_on = 'PATID', how = 'left')\n",
    "first_diag['CCI'] = first_diag['CCI'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-solid",
   "metadata": {},
   "source": [
    "## BMI\n",
    "At the time of biopsy; if missing then on the most recent visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the data for vital\n",
    "Vital1 = Vital[['ID','MEASURE_DATE','ORIGINAL_BMI']]\n",
    "Vital2 = Vital1.drop_duplicates()\n",
    "Vital3 = Vital2.dropna(subset=['ORIGINAL_BMI'])\n",
    "Vital3['First_Date'] = pd.to_datetime(Vital3['MEASURE_DATE'])\n",
    "\n",
    "#Merge with first date of biopsy \n",
    "BMI1 = pd.merge(result_df,Vital3,on = 'ID',how = 'left')\n",
    "BMI2 = BMI1.dropna(subset=['ORIGINAL_BMI'])\n",
    "\n",
    "#Find the BMI of the most recent date\n",
    "BMI2['differ'] = BMI2['First_Date_y'] - BMI2['First_Date_x']\n",
    "BMI2['differ2'] = BMI2['differ'].abs()\n",
    "first_date_rows =  BMI2.groupby('ID')['differ2'].min().reset_index().merge(BMI2, on=['ID', 'differ2'])\n",
    "#right join???\n",
    "\n",
    "#There are duplicate IDs, that is because the same day has multiple BMIs, so let's keep the first one\n",
    "print(len(first_date_rows['ID'].unique()))\n",
    "first_date_rows1 = first_date_rows.drop_duplicates(subset='ID', keep='first')\n",
    "first_date_rows1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    first_date_rows1['ORIGINAL_BMI']<18.5,\n",
    "    (first_date_rows1['ORIGINAL_BMI'] >= 18.5) & (first_date_rows1['ORIGINAL_BMI'] < 25),\n",
    "    (first_date_rows1['ORIGINAL_BMI'] >= 25) & (first_date_rows1['ORIGINAL_BMI'] < 30),\n",
    "    (first_date_rows1['ORIGINAL_BMI'] >= 30) & (first_date_rows1['ORIGINAL_BMI'] < 40),\n",
    "    first_date_rows1['ORIGINAL_BMI']>= 40\n",
    "]\n",
    "\n",
    "choices = ['underweight', 'healthy range','overweight','obesity','severe obesity']\n",
    "\n",
    "first_date_rows1['BMI_group'] = np.select(conditions, choices, default='UN')\n",
    "\n",
    "first_date_rows1['BMI_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-observer",
   "metadata": {},
   "source": [
    "# Merge all the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with BMI\n",
    "Demographic1 = pd.merge(first_diag,first_date_rows1,on = 'ID',how = 'left')\n",
    "Demographic2 = pd.merge(Demographic1,Personzip3,on = 'ID',how = 'left')\n",
    "Demographic2 = pd.merge(Demographic2,Personzip4,on = 'ID',how = 'left')\n",
    "# Demographic2 = Demographic2[['ID','SEX','age','HISPANIC','RACE','CCI','SVI_Person','RUCA1_Person']]\n",
    "\n",
    "#Merge with Insurance\n",
    "Demographic3 = pd.merge(Demographic2,Encounter3,on = 'ID',how = 'left')\n",
    "\n",
    "#Merge with rurality\n",
    "Demographic5 = pd.merge(Demographic3,Encounter4,on = 'ID',how = 'left')\n",
    "\n",
    "#Re-categorize variable\n",
    "#Race\n",
    "conditions = [\n",
    "    Demographic5['RACE'].isin(['01','04','OT']),\n",
    "    Demographic5['RACE'].isin(['07','NI','UN']),\n",
    "    Demographic5['RACE'].isin(['02']),\n",
    "    Demographic5['RACE'].isin(['03']),\n",
    "    Demographic5['RACE'].isin(['05']),\n",
    "    Demographic5['RACE'].isin(['06']),\n",
    "]\n",
    "\n",
    "choices = ['Other', 'Unknown','Asian','Black or African American','White','Multiple race']\n",
    "\n",
    "Demographic5['RACE1'] = np.select(conditions, choices, default='Other')\n",
    "\n",
    "#HISPANIC\n",
    "conditions = [\n",
    "    Demographic5['HISPANIC'].isin(['Y']),\n",
    "    Demographic5['HISPANIC'].isin(['R','NI','UN']),\n",
    "    Demographic5['HISPANIC'].isin(['N']),\n",
    "]\n",
    "\n",
    "choices = ['Yes', 'Unknown','No']\n",
    "\n",
    "Demographic5['HISPANIC1'] = np.select(conditions, choices, default='Other')\n",
    "\n",
    "#RUCA\n",
    "#https://www.hrsa.gov/rural-health/about-us/what-is-rural\n",
    "conditions = [\n",
    "    Demographic5['RUCA1'].isin([1.0,2.0,3.0]),\n",
    "    Demographic5['RUCA1'].isin([4.0,5.0,6.0,7.0,8.0,9.0,10.0]),\n",
    "]\n",
    "\n",
    "choices = ['Urban', 'Rural']\n",
    "\n",
    "Demographic5['RUCA'] = np.select(conditions, choices, default='UN')\n",
    "\n",
    "#Age\n",
    "conditions = [\n",
    "    (Demographic5['age'] >= 18) & (Demographic5['age'] < 40),\n",
    "    (Demographic5['age'] >= 40) & (Demographic5['age'] <= 65),\n",
    "    Demographic5['age']>65\n",
    "]\n",
    "\n",
    "choices = ['18-39', '40-64','>65']\n",
    "\n",
    "Demographic5['age_group'] = np.select(conditions, choices, default='UN')\n",
    "\n",
    "#CCI\n",
    "conditions = [\n",
    "    Demographic5['CCI'] == 0,\n",
    "    Demographic5['CCI'].isin([1.0,2.0]),\n",
    "    Demographic5['CCI'].isin([3.0,4.0]),\n",
    "    Demographic5['age']>=5.0\n",
    "]\n",
    "\n",
    "choices = ['None', 'Mild','Moderate','Severe']\n",
    "\n",
    "Demographic5['CCI1'] = np.select(conditions, choices, default='UN')\n",
    "\n",
    "#RUCA_person\n",
    "conditions = [\n",
    "    Demographic5['RUCA1_Person'].isin([1.0,2.0,3.0]),\n",
    "    Demographic5['RUCA1_Person'].isin([4.0,5.0,6.0,7.0,8.0,9.0,10.0]),\n",
    "]\n",
    "\n",
    "choices = ['Urban', 'Rural']\n",
    "\n",
    "Demographic5['RUCA_Person'] = np.select(conditions, choices, default='UN')\n",
    "\n",
    "\n",
    "#SVI\n",
    "conditions = [\n",
    "    Demographic5['SVI_Person']<=0.5,\n",
    "    (Demographic5['SVI_Person'] > 0.50) & (Demographic5['SVI_Person'] <= 0.75),\n",
    "    Demographic5['SVI_Person']>0.75\n",
    "]\n",
    "\n",
    "choices = ['<0.5', '0.5-0.75','>0.75']\n",
    "\n",
    "Demographic5['SVI_Person2'] = np.select(conditions, choices, default='UN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with SVI\n",
    "Demographic6 = pd.merge(Demographic5,Encounter6,on = 'ID',how = 'left')\n",
    "\n",
    "# Function to check if value is in list A\n",
    "def check_presence(value):\n",
    "    return 1 if value in cancer_afterID else 0\n",
    "\n",
    "# Apply the function to create column B\n",
    "Demographic6['Cancer'] = Demographic6['ID'].apply(lambda x: check_presence(x))\n",
    "\n",
    "#SVI\n",
    "conditions = [\n",
    "    Demographic6['RPL_THEMES']<=0.5,\n",
    "    (Demographic6['RPL_THEMES'] > 0.50) & (Demographic6['RPL_THEMES'] <= 0.75),\n",
    "    Demographic6['RPL_THEMES']>0.75\n",
    "]\n",
    "\n",
    "choices = ['<0.5', '0.5-0.75','>0.75']\n",
    "\n",
    "Demographic6['SVI'] = np.select(conditions, choices, default='UN')\n",
    "\n",
    "# #Must delete them to avoid multi-colinear\n",
    "# # Delete rows where value in sex is 'UN' (Only 1 people)\n",
    "# Demographic6 = Demographic6.loc[Demographic5['SEX'] != 'UN']\n",
    "# Demographic6 = Demographic6.loc[Demographic6['SVI'] != 'UN'] #only 4 people\n",
    "\n",
    "# #SVI will not be in the model as category, don't delete\n",
    "# Demographic6 = Demographic6.loc[Demographic6['RUCA_Person'] != 'UN']\n",
    "# #Demographic6.to_csv('Demographic6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-henry",
   "metadata": {},
   "source": [
    "# 4. Time to cancer analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-lambda",
   "metadata": {},
   "source": [
    "## Ultrasound to biopsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "biopsy_afterpatient1 = biopsy_afterpatient[['ID','Biopsy date']]\n",
    "\n",
    "first_diag2 =  pd.merge(first_diag,biopsy_afterpatient1, on = 'ID',how = 'left')\n",
    "first_diag2['Biopsy date'] = first_diag2['Biopsy date'].fillna('2022-06-30')\n",
    "#Calculate time to biopsy from first ultrasound\n",
    "first_diag2['Time to survival']  = first_diag2['Biopsy date'] - first_diag2['First_Date']\n",
    "#Make the columns numeric\n",
    "first_diag2['Time to survival1']  = first_diag2['Time to survival'] / pd.Timedelta(days=1)\n",
    "first_diag2['Time to survival2'] = first_diag2['Time to survival'] / pd.Timedelta(days=365.25)\n",
    "\n",
    "# Function to check if value is in list A\n",
    "def check_presence(value):\n",
    "    return 1 if value in biopsy_afterID else 0\n",
    "\n",
    "# Apply the function to create column B\n",
    "first_diag2['Biopsy'] = first_diag2['ID'].apply(lambda x: check_presence(x))\n",
    "\n",
    "plt.hist(first_diag2['Time to survival2'], bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all the patients\n",
    "from lifelines import KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter() \n",
    "kmf.fit(durations = first_diag2['Time to survival2'], event_observed = first_diag2['Biopsy']) \n",
    "kmf.plot_survival_function()\n",
    "\n",
    "# Add x-label\n",
    "plt.xlabel('Time (in years)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-collection",
   "metadata": {},
   "source": [
    "## Biopsy to cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerafterpatient1 = cancerafterpatient[['ID','Cancer date']]\n",
    "biopsy_afterpatient =  pd.merge(biopsy_afterpatient,cancerafterpatient1, on = 'ID',how = 'left')\n",
    "biopsy_afterpatient['Cancer date'] = biopsy_afterpatient['Cancer date'].fillna('2022-06-30')\n",
    "#Calculate time to cancer from first biopsy \n",
    "biopsy_afterpatient['Time to survival']  = biopsy_afterpatient['Cancer date'] - biopsy_afterpatient['Biopsy date']\n",
    "#Make the columns numeric\n",
    "biopsy_afterpatient['Time to survival1']  = biopsy_afterpatient['Time to survival'] / pd.Timedelta(days=1)\n",
    "biopsy_afterpatient['Time to survival2'] = biopsy_afterpatient['Time to survival'] / pd.Timedelta(days=365.25)\n",
    "\n",
    "# Function to check if value is in list A\n",
    "def check_presence(value):\n",
    "    return 1 if value in cancer_afterID else 0\n",
    "\n",
    "# Apply the function to create column B\n",
    "biopsy_afterpatient['Cancer'] = biopsy_afterpatient['ID'].apply(lambda x: check_presence(x))\n",
    "\n",
    "plt.hist(biopsy_afterpatient['Time to survival2'], bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter() \n",
    "kmf.fit(durations = biopsy_afterpatient['Time to survival2'], event_observed = biopsy_afterpatient['Cancer']) \n",
    "kmf.plot_survival_function()\n",
    "\n",
    "# Add x-label\n",
    "plt.xlabel('Time (in years)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-retreat",
   "metadata": {},
   "source": [
    "## 18 month cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "biopsy_afterpatient1 = biopsy_afterpatient[['ID','Biopsy date']]\n",
    "\n",
    "first_diag2 =  pd.merge(biopsy_afterpatient1,first_diag, on = 'ID',how = 'left')\n",
    "#Calculate time to biopsy from first ultrasound\n",
    "first_diag2['Time to survival']  = first_diag2['Biopsy date'] - first_diag2['First_Date']\n",
    "#Make the columns numeric\n",
    "first_diag2['Time to survival1']  = first_diag2['Time to survival'] / pd.Timedelta(days=1)\n",
    "first_diag2['Time to survival2'] = first_diag2['Time to survival'] / pd.Timedelta(days=365.25)\n",
    "\n",
    "def check_presence(value):\n",
    "    return 1 if value < 548 else 0\n",
    "first_diag2['Biopsy_18month'] = first_diag2['Time to survival1'].apply(check_presence)\n",
    "first_diag2 = first_diag2[['ID','Time to survival1','Biopsy_18month']]\n",
    "first_diag2 = first_diag2.rename(columns={'Time to survival1': 'Time to survival_biopsy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_diag3 =  pd.merge(first_diag,first_diag2, on = 'ID',how = 'left')\n",
    "first_diag3['Time to survival_biopsy'] = first_diag3['Time to survival_biopsy'].fillna(548.0)\n",
    "first_diag3['Biopsy_18month'] = first_diag3['Biopsy_18month'].fillna(0)\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter() \n",
    "kmf.fit(durations = first_diag3['Time to survival_biopsy'], event_observed = first_diag3['Biopsy_18month']) \n",
    "kmf.plot_survival_function()\n",
    "\n",
    "# Add x-label\n",
    "plt.xlabel('Time (in days)')\n",
    "plt.xlim(-20, 548)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_diag_withcancer2 = biopsy_afterpatient[biopsy_afterpatient['ID'].isin(cancer_afterID)]\n",
    "first_diag_withcancer2['Cancer_18month'] = first_diag_withcancer2['Time to survival1'].apply(check_presence)\n",
    "first_diag_withcancer2 = first_diag_withcancer2[['ID','Time to survival1','Cancer_18month']]\n",
    "first_diag_withcancer2 = first_diag_withcancer2.rename(columns={'Time to survival1': 'Time to survival_cancer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_diag3 =  pd.merge(biopsy_afterpatient,first_diag_withcancer2, on = 'ID',how = 'left')\n",
    "first_diag3['Time to survival_cancer'] = first_diag3['Time to survival_cancer'].fillna(548.0)\n",
    "first_diag3['Cancer_18month'] = first_diag3['Cancer_18month'].fillna(0)\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter() \n",
    "kmf.fit(durations = first_diag3['Time to survival_cancer'], event_observed = first_diag3['Cancer_18month']) \n",
    "kmf.plot_survival_function()\n",
    "\n",
    "# Add x-label\n",
    "plt.xlabel('Time (in days)')\n",
    "plt.xlim(-20, 548)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_18month1 = pd.merge(Demographic6,first_diag_withcancer2, on = 'ID',how = 'left')\n",
    "Demographic6_18month1['Cancer_18month'] = Demographic6_18month1['Cancer_18month'].fillna(0)\n",
    "Demographic6_18month = pd.merge(Demographic6_18month1,first_diag2, on = 'ID',how = 'left')\n",
    "Demographic6_18month['Biopsy_18month'] = Demographic6_18month['Biopsy_18month'].fillna(0)\n",
    "print(len(Demographic6_18month1[Demographic6_18month1['Cancer_18month']  == 1]))\n",
    "print(len(Demographic6_18month[Demographic6_18month['Biopsy_18month']  == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-violin",
   "metadata": {},
   "source": [
    "# 5. Build the logistic model for aim 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-rocket",
   "metadata": {},
   "source": [
    "## Ultrasound to Biopsy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-hello",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_18month = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Demographic6_18month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_18month1 = Demographic6_18month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_18month = Demographic6_18month.loc[Demographic6_18month['SEX'] != 'UN']\n",
    "Demographic6_18month = Demographic6_18month.loc[Demographic6_18month['Insurance'] != 'Other']\n",
    "Demographic6_18month = Demographic6_18month.loc[Demographic6_18month['RUCA_Person'] != 'UN']\n",
    "\n",
    "Demographic_final = Demographic6_18month.drop(columns=['Unnamed: 0','Unnamed: 0.1','Time to survival_cancer','Time to survival_biopsy', 'Cancer_18month','Cancer','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "Demographic_final['RPL_THEMES1'] = pd.qcut(Demographic_final['RPL_THEMES'], q=4, labels=False)\n",
    "Demographic_final['SVI_Person1'] = pd.qcut(Demographic_final['SVI_Person'], q=4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic6_18month = Demographic6 #VIF\n",
    "\n",
    "#Delete rows where value in sex is 'UN' (Only 1 people)\n",
    "\n",
    "Demographic6_18month = Demographic6_18month.loc[Demographic6_18month['SEX'] != 'UN']\n",
    "Demographic6_18month = Demographic6_18month.loc[Demographic6_18month['Insurance'] != 'Other']\n",
    "Demographic6_18month = Demographic6_18month.loc[Demographic6_18month['RUCA_Person'] != 'UN']\n",
    "\n",
    "Demographic_final = Demographic6_18month.drop(columns=['Unnamed: 0','Unnamed: 0.1','Time to survival_cancer','Time to survival_biopsy', 'Cancer_18month','Cancer','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "Demographic_final['RPL_THEMES1'] = pd.qcut(Demographic_final['RPL_THEMES'], q=4, labels=False)\n",
    "Demographic_final['SVI_Person1'] = pd.qcut(Demographic_final['SVI_Person'], q=4, labels=False)\n",
    "\n",
    "Demographic_final = Demographic_final.drop(columns=['RPL_THEMES','SVI_Person','RUCA_Person','RUCA'])\n",
    "\n",
    "Demographic_final = Demographic_final.dropna()\n",
    "\n",
    "#One hot encoding for categorical variables\n",
    "Dummy = ['HISPANIC1','RACE1','SEX','Insurance','CCI1','RPL_THEMES1','SVI_Person1']\n",
    "\n",
    "\n",
    "def convert_to_dummies(dataframe, variables):\n",
    "    for variable in variables:\n",
    "        if  variable == 'Insurance':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_MEDICAID'])\n",
    "        elif variable == 'RACE1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_White'])\n",
    "        elif variable == 'CCI1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_None'])\n",
    "        elif variable == 'RPL_THEMES1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_3.0'])\n",
    "        elif variable == 'SVI_Person1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_3.0'])\n",
    "        elif variable == 'age':\n",
    "            continue  # Skip further processing for these variables\n",
    "        else:\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable, drop_first=True)\n",
    "        \n",
    "        if variable != 'age':\n",
    "            dummies = dummies.astype(int)\n",
    "            dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "            dataframe.drop(columns=[variable], inplace=True)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "#VIF\n",
    "# Demographic_final = Demographic6_18month.drop(columns=['Unnamed: 0','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "Demographic_final_dummy = convert_to_dummies(Demographic_final, Dummy)\n",
    "Demographic_final_dummy = Demographic_final_dummy.dropna()\n",
    "Demographic_final_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic7 = Demographic6_18month[['HISPANIC1','RACE1','SEX','Insurance','RUCA','SVI','age_group','CCI1','RUCA_Person','SVI_Person2']]\n",
    "\n",
    "# Create an empty list to store tuples of (variable, level, count)\n",
    "value_counts_list = []\n",
    "\n",
    "# Iterate through each variable and calculate value_counts\n",
    "for col in Demographic7:\n",
    "    value_counts = pd.Series(Demographic7[col]).value_counts()\n",
    "    for index, count in value_counts.items():\n",
    "        value_counts_list.append((col, index, count))\n",
    "\n",
    "# Convert the list of tuples into a DataFrame\n",
    "value_counts_df = pd.DataFrame(value_counts_list, columns=['Variable', 'Level', 'Count'])\n",
    "value_counts_df['Percent'] = value_counts_df['Count']/67238\n",
    "\n",
    "value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without Rurality\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools import add_constant\n",
    "import statsmodels.api as sm\n",
    "import researchpy as rp\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = Demographic_final_dummy.drop(columns=['Biopsy_18month'])  # Input features\n",
    "y = Demographic_final_dummy['Biopsy_18month']\n",
    "#X = add_constant(X)\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Convert summary to a DataFrame\n",
    "summary_df = pd.DataFrame(result.summary().tables[1])\n",
    "\n",
    "# Save the summary DataFrame to a CSV file\n",
    "# summary_df.to_csv('logistic_model_summary_test.csv', index=False)\n",
    "\n",
    "# Display model summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_dataframes(df, excel_filename):\n",
    "    # Get the column names\n",
    "    column_names = df.columns.tolist()\n",
    "    column_names.remove('Biopsy_18month')\n",
    "    \n",
    "    # Create an empty DataFrame to store results\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through the variables of interest\n",
    "    for column_name in column_names:\n",
    "        # Create a new dataframe for the variable with the event and time-to-survival columns\n",
    "        variable_df = pd.DataFrame({\n",
    "            column_name: df[column_name],\n",
    "            'Biopsy_18month': df['Biopsy_18month']\n",
    "        })\n",
    "        \n",
    "        # Convert specific variables to dummy variables while dropping categories\n",
    "        variables_to_convert = [column_name]  # Add more variables if needed\n",
    "        Demographic_final_dummy = convert_to_dummies(variable_df, variables_to_convert)\n",
    "        Demographic_final_dummy = Demographic_final_dummy.dropna()\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X = Demographic_final_dummy.drop(columns=['Biopsy_18month']) \n",
    "        y = Demographic_final_dummy['Biopsy_18month']\n",
    "        X = add_constant(X)\n",
    "\n",
    "        # Fit logistic regression model\n",
    "        model = sm.Logit(y, X)\n",
    "        result = model.fit()\n",
    "\n",
    "        # Store model results in the master DataFrame\n",
    "        model_summary = pd.DataFrame(result.summary().tables[1])\n",
    "        model_summary['Variable'] = column_name  # Add a column for the variable name\n",
    "        result_df = pd.concat([result_df, model_summary])\n",
    "    \n",
    "    # Save the master DataFrame to an Excel file\n",
    "    result_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "# Call the function to create the single DataFrame with all model results\n",
    "create_variable_dataframes(Demographic_final, 'logistic1.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-preserve",
   "metadata": {},
   "source": [
    "## Biopsy to cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-muscle",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_18month2 = Demographic6_18month[Demographic6_18month['ID'].isin(biopsy_afterID)]\n",
    "Demographic6_18month2 = Demographic6_18month2.loc[Demographic6_18month2['RUCA_Person'] != 'UN']\n",
    "Demographic_final = Demographic6_18month2.drop(columns=['Unnamed: 0','Unnamed: 0.1','Time to survival_cancer','Time to survival_biopsy','Cancer','Biopsy_18month','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "Demographic_final['RPL_THEMES1'] = pd.qcut(Demographic_final['RPL_THEMES'], q=4, labels=False)\n",
    "Demographic_final['SVI_Person1'] = pd.qcut(Demographic_final['SVI_Person'], q=4, labels=False)\n",
    "\n",
    "Demographic_final = Demographic_final.drop(columns=['RPL_THEMES','SVI_Person','RUCA_Person','RUCA'])\n",
    "\n",
    "Demographic_final = Demographic_final.dropna()\n",
    "\n",
    "#VIF\n",
    "# Demographic_final = Demographic6_18month.drop(columns=['Unnamed: 0','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "def convert_to_dummies(dataframe, variables):\n",
    "    for variable in variables:\n",
    "        if  variable == 'Insurance':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_MEDICAID'])\n",
    "        elif variable == 'RACE1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_White'])\n",
    "        elif variable == 'CCI1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_None'])\n",
    "        elif variable == 'RPL_THEMES1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_3'])\n",
    "        elif variable == 'SVI_Person1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_3.0'])\n",
    "        elif variable == 'age':\n",
    "            continue  # Skip further processing for these variables\n",
    "        else:\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable, drop_first=True)\n",
    "        \n",
    "        if variable != 'age':\n",
    "            dummies = dummies.astype(int)\n",
    "            dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "            dataframe.drop(columns=[variable], inplace=True)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "Demographic_final_dummy = convert_to_dummies(Demographic_final, Dummy)\n",
    "Demographic_final_dummy = Demographic_final_dummy.dropna()\n",
    "\n",
    "Demographic7 = Demographic6_18month2[['HISPANIC1','RACE1','SEX','Insurance','RUCA','SVI','age_group','CCI1','RUCA_Person','SVI_Person2']]\n",
    "\n",
    "# Create an empty list to store tuples of (variable, level, count)\n",
    "value_counts_list = []\n",
    "\n",
    "# Iterate through each variable and calculate value_counts\n",
    "for col in Demographic7:\n",
    "    value_counts = pd.Series(Demographic7[col]).value_counts()\n",
    "    for index, count in value_counts.items():\n",
    "        value_counts_list.append((col, index, count))\n",
    "\n",
    "# Convert the list of tuples into a DataFrame\n",
    "value_counts_df = pd.DataFrame(value_counts_list, columns=['Variable', 'Level', 'Count'])\n",
    "value_counts_df['Percent'] = value_counts_df['Count']/67238\n",
    "\n",
    "#value_counts_df.to_csv('value_counts.csv')\n",
    "value_counts_df\n",
    "\n",
    "Demographic_final_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = Demographic_final_dummy.drop(columns=['Cancer_18month'])  # Input features\n",
    "y = Demographic_final_dummy['Cancer_18month']\n",
    "#X = add_constant(X)\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Convert summary to a DataFrame\n",
    "summary_df = pd.DataFrame(result.summary().tables[1])\n",
    "\n",
    "# Save the summary DataFrame to a CSV file\n",
    "# summary_df.to_csv('logistic_model_summary2.csv', index=False)\n",
    "\n",
    "# Display model summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming 'X' and 'y' have been defined as before:\n",
    "X = sm.add_constant(X)  # Adding a constant is important for VIF calculation\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Now, get the covariance matrix from the fitted results\n",
    "cov = result.cov_params()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr = cov / np.outer(result.bse, result.bse)\n",
    "\n",
    "# Inverting the correlation matrix gives us variance inflation factors on the diagonal\n",
    "vif = np.diag(np.linalg.inv(corr))\n",
    "\n",
    "# We can put this into a DataFrame for a better presentation\n",
    "vif_df = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'VIF': vif\n",
    "})\n",
    "\n",
    "print(vif_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_dataframes(df, excel_filename):\n",
    "    # Get the column names\n",
    "    column_names = df.columns.tolist()\n",
    "    column_names.remove('Cancer_18month')\n",
    "    \n",
    "    # Create an empty DataFrame to store results\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through the variables of interest\n",
    "    for column_name in column_names:\n",
    "        # Create a new dataframe for the variable with the event and time-to-survival columns\n",
    "        variable_df = pd.DataFrame({\n",
    "            column_name: df[column_name],\n",
    "            'Cancer_18month': df['Cancer_18month']\n",
    "        })\n",
    "        \n",
    "        # Convert specific variables to dummy variables while dropping categories\n",
    "        variables_to_convert = [column_name]  # Add more variables if needed\n",
    "        Demographic_final_dummy = convert_to_dummies(variable_df, variables_to_convert)\n",
    "        Demographic_final_dummy = Demographic_final_dummy.dropna()\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X = Demographic_final_dummy.drop(columns=['Cancer_18month']) \n",
    "        y = Demographic_final_dummy['Cancer_18month']\n",
    "        X = add_constant(X)\n",
    "\n",
    "        # Fit logistic regression model\n",
    "        model = sm.Logit(y, X)\n",
    "        result = model.fit()\n",
    "\n",
    "        # Store model results in the master DataFrame\n",
    "        model_summary = pd.DataFrame(result.summary().tables[1])\n",
    "        model_summary['Variable'] = column_name  # Add a column for the variable name\n",
    "        result_df = pd.concat([result_df, model_summary])\n",
    "    \n",
    "    # Save the master DataFrame to an Excel file\n",
    "    result_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "# Call the function to create the single DataFrame with all model results\n",
    "create_variable_dataframes(Demographic_final, 'logistic2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-princeton",
   "metadata": {},
   "source": [
    "# 6. Build the Linear regression model for aim 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-catalyst",
   "metadata": {},
   "source": [
    "## Ultrasound to biopsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_18month = pd.read_csv('/data2/datasets/Xingke/Thyroid_Biopsy/Demographic6_18month.csv')\n",
    "Demographic6_18month = Demographic6_18month.drop(columns=['Unnamed: 0','Unnamed: 0.1'])\n",
    "Demographic6_18month1 = Demographic6_18month\n",
    "\n",
    "Demographic6_biopsy = Demographic6_18month[Demographic6_18month['Biopsy_18month']  == 1]\n",
    "Demographic_final = Demographic6_biopsy.drop(columns=['Unnamed: 0','Unnamed: 0.1','Time to survival_cancer','Cancer_18month','Biopsy_18month','Cancer','Biopsy_18month','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "Demographic_final['RPL_THEMES1'] = pd.qcut(Demographic_final['RPL_THEMES'], q=4, labels=False)\n",
    "Demographic_final['SVI_Person1'] = pd.qcut(Demographic_final['SVI_Person'], q=4, labels=False)\n",
    "\n",
    "Demographic_final = Demographic_final.drop(columns=['RPL_THEMES','SVI_Person','RUCA_Person','RUCA'])\n",
    "\n",
    "Demographic_final = Demographic_final.dropna()\n",
    "\n",
    "#VIF\n",
    "# Demographic_final = Demographic6_18month.drop(columns=['Unnamed: 0','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "def convert_to_dummies(dataframe, variables):\n",
    "    for variable in variables:\n",
    "        if  variable == 'Insurance':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_MEDICAID'])\n",
    "        elif variable == 'RACE1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_White'])\n",
    "        elif variable == 'CCI1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_None'])\n",
    "        elif variable == 'RPL_THEMES1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_3'])\n",
    "        elif variable == 'SVI_Person1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_3.0'])\n",
    "        elif variable == 'age':\n",
    "            continue  # Skip further processing for these variables\n",
    "        else:\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable, drop_first=True)\n",
    "        \n",
    "        if variable != 'age':\n",
    "            dummies = dummies.astype(int)\n",
    "            dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "            dataframe.drop(columns=[variable], inplace=True)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "Demographic_final_dummy = convert_to_dummies(Demographic_final, Dummy)\n",
    "Demographic_final_dummy = Demographic_final_dummy.dropna()\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = Demographic_final_dummy.drop(columns=['Time to survival_biopsy'])  # Input features\n",
    "# Assuming 'Time to survival_biopsy' is non-negative\n",
    "# Demographic_final_dummy['log_Time_to_survival_biopsy'] = np.log1p(Demographic_final_dummy['Time to survival_biopsy'])\n",
    "# y = Demographic_final_dummy['log_Time_to_survival_biopsy'] \n",
    "y = Demographic_final_dummy['Time to survival_biopsy'] \n",
    "\n",
    "# Fit linear regression model\n",
    "X = add_constant(X)  # Add constant term\n",
    "model = sm.OLS(y, X)  # Ordinary Least Squares (OLS) regression\n",
    "result = model.fit()\n",
    "\n",
    "# Convert summary to a DataFrame\n",
    "summary_df = pd.DataFrame(result.summary().tables[1])\n",
    "\n",
    "# Save the summary DataFrame to a CSV file\n",
    "# summary_df.to_csv('regression_model_summary3.csv', index=False)\n",
    "\n",
    "# Display model summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic7 = Demographic6_biopsy[['HISPANIC1','RACE1','SEX','Insurance','RUCA','SVI','age_group','CCI1','RUCA_Person','SVI_Person2']]\n",
    "\n",
    "# Create an empty list to store tuples of (variable, level, count)\n",
    "value_counts_list = []\n",
    "\n",
    "# Iterate through each variable and calculate value_counts\n",
    "for col in Demographic7:\n",
    "    value_counts = pd.Series(Demographic7[col]).value_counts()\n",
    "    for index, count in value_counts.items():\n",
    "        value_counts_list.append((col, index, count))\n",
    "\n",
    "# Convert the list of tuples into a DataFrame\n",
    "value_counts_df = pd.DataFrame(value_counts_list, columns=['Variable', 'Level', 'Count'])\n",
    "value_counts_df['Percent'] = value_counts_df['Count']/67238\n",
    "\n",
    "#value_counts_df.to_csv('value_counts.csv')\n",
    "value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_dataframes(df, excel_filename):\n",
    "    # Get the column names\n",
    "    column_names = df.columns.tolist()\n",
    "    column_names.remove('Time to survival_biopsy')\n",
    "    \n",
    "    # Create an empty DataFrame to store results\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through the variables of interest\n",
    "    for column_name in column_names:\n",
    "        # Create a new dataframe for the variable with the event and time-to-survival columns\n",
    "        variable_df = pd.DataFrame({\n",
    "            column_name: df[column_name],\n",
    "            'Time to survival_biopsy': df['Time to survival_biopsy']\n",
    "        })\n",
    "        \n",
    "        # Convert specific variables to dummy variables while dropping categories\n",
    "        variables_to_convert = [column_name]  # Add more variables if needed\n",
    "        Demographic_final_dummy = convert_to_dummies(variable_df, variables_to_convert)\n",
    "        Demographic_final_dummy = Demographic_final_dummy.dropna()\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X = Demographic_final_dummy.drop(columns=['Time to survival_biopsy']) \n",
    "        y = Demographic_final_dummy['Time to survival_biopsy']\n",
    "        X = add_constant(X)\n",
    "\n",
    "        # Fit linear regression model\n",
    "        model = sm.OLS(y, X)  # Change to OLS for linear regression\n",
    "        result = model.fit()\n",
    "\n",
    "        # Store model results in the master DataFrame\n",
    "        model_summary = pd.DataFrame(result.summary().tables[1])\n",
    "        model_summary['Variable'] = column_name  # Add a column for the variable name\n",
    "        result_df = pd.concat([result_df, model_summary])\n",
    "    \n",
    "    # Save the master DataFrame to an Excel file\n",
    "    result_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "# Call the function to create the single DataFrame with all model results\n",
    "create_variable_dataframes(Demographic_final, 'linear_regression.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-bundle",
   "metadata": {},
   "source": [
    "## Biopsy to cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_18month1 = Demographic6_18month1.loc[Demographic6_18month1['Insurance'] != 'Other']\n",
    "Demographic6_18month1 = Demographic6_18month1.loc[Demographic6_18month1['Insurance'] != 'NOPAY']\n",
    "Demographic6_18month1 = Demographic6_18month1.loc[Demographic6_18month1['RACE1'] != 'Multiple race']\n",
    "\n",
    "Demographic6_biopsy = Demographic6_18month1[Demographic6_18month1['Cancer_18month']  == 1]\n",
    "Demographic_final = Demographic6_biopsy.drop(columns=['Unnamed: 0','Unnamed: 0.1','Time to survival_biopsy','Biopsy_18month','Cancer_18month','Cancer','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "Demographic_final['RPL_THEMES1'] = pd.qcut(Demographic_final['RPL_THEMES'], q=4, labels=False)\n",
    "Demographic_final['SVI_Person1'] = pd.qcut(Demographic_final['SVI_Person'], q=4, labels=False)\n",
    "\n",
    "Demographic_final = Demographic_final.drop(columns=['RPL_THEMES','SVI_Person','RUCA_Person','RUCA'])\n",
    "\n",
    "Demographic_final = Demographic_final.dropna()\n",
    "\n",
    "#VIF\n",
    "# Demographic_final = Demographic6_18month.drop(columns=['Unnamed: 0','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "def convert_to_dummies(dataframe, variables):\n",
    "    for variable in variables:\n",
    "        if  variable == 'Insurance':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_MEDICAID'])\n",
    "        elif variable == 'RACE1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_White'])\n",
    "        elif variable == 'CCI1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_None'])\n",
    "        elif variable == 'RPL_THEMES1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_3'])\n",
    "        elif variable == 'SVI_Person1':\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable)\n",
    "            dummies = dummies.drop(columns=[f'{variable}_3.0'])\n",
    "        elif variable == 'age':\n",
    "            continue  # Skip further processing for these variables\n",
    "        else:\n",
    "            dummies = pd.get_dummies(dataframe[variable], prefix=variable, drop_first=True)\n",
    "        \n",
    "        if variable != 'age':\n",
    "            dummies = dummies.astype(int)\n",
    "            dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "            dataframe.drop(columns=[variable], inplace=True)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "Demographic_final_dummy = convert_to_dummies(Demographic_final, Dummy)\n",
    "Demographic_final_dummy = Demographic_final_dummy.dropna()\n",
    "\n",
    "# Demographic6_18month2 = Demographic6_18month[Demographic6_18month['ID'].isin(biopsy_afterID)]\n",
    "# Demographic_final = Demographic6_18month2.drop(columns=[ 'Time to survival_biopsy','Cancer_18month','Biopsy_18month','Cancer','Biopsy_18month','ID','RACE','HISPANIC','RUCA2','RUCA1','SVI','age_group','CCI','SVI_Person2','RUCA1_Person'])\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = Demographic_final_dummy.drop(columns=['Time to survival_cancer'])  # Input features\n",
    "# Demographic_final_dummy['log_Time_to_survival_cancer'] = np.log1p(Demographic_final_dummy['Time to survival_cancer'])\n",
    "\n",
    "# y = Demographic_final_dummy['log_Time_to_survival_cancer'] \n",
    "y = Demographic_final_dummy['Time to survival_cancer']\n",
    "\n",
    "# Fit linear regression model\n",
    "X = add_constant(X)  # Add constant term\n",
    "model = sm.OLS(y, X)  # Ordinary Least Squares (OLS) regression\n",
    "result = model.fit()\n",
    "\n",
    "# Convert summary to a DataFrame\n",
    "summary_df = pd.DataFrame(result.summary().tables[1])\n",
    "\n",
    "# Save the summary DataFrame to a CSV file\n",
    "summary_df.to_csv('regression_model_summary4.csv', index=False)\n",
    "\n",
    "# Display model summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic7 = Demographic6_biopsy[['HISPANIC1','RACE1','SEX','Insurance','RUCA','SVI','age_group','CCI1','RUCA_Person','SVI_Person2']]\n",
    "\n",
    "# Create an empty list to store tuples of (variable, level, count)\n",
    "value_counts_list = []\n",
    "\n",
    "# Iterate through each variable and calculate value_counts\n",
    "for col in Demographic7:\n",
    "    value_counts = pd.Series(Demographic7[col]).value_counts()\n",
    "    for index, count in value_counts.items():\n",
    "        value_counts_list.append((col, index, count))\n",
    "\n",
    "# Convert the list of tuples into a DataFrame\n",
    "value_counts_df = pd.DataFrame(value_counts_list, columns=['Variable', 'Level', 'Count'])\n",
    "value_counts_df['Percent'] = value_counts_df['Count']/67238\n",
    "\n",
    "#value_counts_df.to_csv('value_counts.csv')\n",
    "value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_dataframes(df, excel_filename):\n",
    "    # Get the column names\n",
    "    column_names = df.columns.tolist()\n",
    "    column_names.remove('Time to survival_cancer')\n",
    "    \n",
    "    # Create an empty DataFrame to store results\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through the variables of interest\n",
    "    for column_name in column_names:\n",
    "        # Create a new dataframe for the variable with the event and time-to-survival columns\n",
    "        variable_df = pd.DataFrame({\n",
    "            column_name: df[column_name],\n",
    "            'Time to survival_cancer': df['Time to survival_cancer']\n",
    "        })\n",
    "        \n",
    "        # Convert specific variables to dummy variables while dropping categories\n",
    "        variables_to_convert = [column_name]  # Add more variables if needed\n",
    "        Demographic_final_dummy = convert_to_dummies(variable_df, variables_to_convert)\n",
    "        Demographic_final_dummy = Demographic_final_dummy.dropna()\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X = Demographic_final_dummy.drop(columns=['Time to survival_cancer']) \n",
    "        y = Demographic_final_dummy['Time to survival_cancer']\n",
    "        X = add_constant(X)\n",
    "\n",
    "        # Fit linear regression model\n",
    "        model = sm.OLS(y, X)  # Change to OLS for linear regression\n",
    "        result = model.fit()\n",
    "\n",
    "        # Store model results in the master DataFrame\n",
    "        model_summary = pd.DataFrame(result.summary().tables[1])\n",
    "        model_summary['Variable'] = column_name  # Add a column for the variable name\n",
    "        result_df = pd.concat([result_df, model_summary])\n",
    "    \n",
    "    # Save the master DataFrame to an Excel file\n",
    "    result_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "# Call the function to create the single DataFrame with all model results\n",
    "create_variable_dataframes(Demographic_final, 'linear_regression2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-boxing",
   "metadata": {},
   "source": [
    "# 7. Descriptive counts for the cohort ( The first step of the project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6['RACE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_diag['age'].mean())\n",
    "print(first_diag['age'].median())\n",
    "print(first_diag['age'].std())\n",
    "first_diag['age'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6['HISPANIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6['Insurance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = list(range(0, 80, 5))\n",
    "\n",
    "plt.hist(first_date_rows1['ORIGINAL_BMI'], bins=bin_edges)  # Adjust the number of bins as needed\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of BMI')\n",
    "plt.xticks(bin_edges,rotation=45)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_date_rows1['ORIGINAL_BMI'].mean())\n",
    "print(first_date_rows1['ORIGINAL_BMI'].median())\n",
    "print(first_date_rows1['ORIGINAL_BMI'].std())\n",
    "first_date_rows1['ORIGINAL_BMI'].quantile([0.25, 0.5, 0.75])\n",
    "print(first_date_rows1['ORIGINAL_BMI'].max())\n",
    "BMI11 = first_date_rows1[first_date_rows1['ORIGINAL_BMI']<1000]\n",
    "print(BMI11['ORIGINAL_BMI'].std())\n",
    "BMI11['ORIGINAL_BMI'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Demographic6['RPL_THEMES'].mean())\n",
    "print(Demographic6['RPL_THEMES'].median())\n",
    "print(Demographic6['RPL_THEMES'].std())\n",
    "Demographic6['RPL_THEMES'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6['RPL_THEMES'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Demographic6['SVI_Person'].mean())\n",
    "print(Demographic6['SVI_Person'].median())\n",
    "print(Demographic6['SVI_Person'].std())\n",
    "Demographic6['SVI_Person'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6['SVI_Person'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6['CCI1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6['RUCA_Person'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6['RUCA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-builder",
   "metadata": {},
   "source": [
    "## For biopsy cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic6_biopsy = Demographic6[Demographic6['ID'].isin(biopsy_afterID)]\n",
    "Demographic6_biopsy = Demographic6_18month[Demographic6_18month['Biopsy_18month']  == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Demographic6_biopsy['age'].mean())\n",
    "print(Demographic6_biopsy['age'].median())\n",
    "print(Demographic6_biopsy['age'].std())\n",
    "Demographic6_biopsy['age'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Demographic6_biopsy['SVI_Person'].mean())\n",
    "print(Demographic6_biopsy['SVI_Person'].median())\n",
    "print(Demographic6_biopsy['SVI_Person'].std())\n",
    "Demographic6_biopsy['SVI_Person'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy[Demographic6_biopsy['SVI_Person'].isna()] # RPL_THEMES=SVI for facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy[Demographic6_biopsy['RPL_THEMES'].isna()] # RPL_THEMES=SVI for facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Demographic6_biopsy['RPL_THEMES'].mean())\n",
    "print(Demographic6_biopsy['RPL_THEMES'].median())\n",
    "print(Demographic6_biopsy['RPL_THEMES'].std())\n",
    "Demographic6_biopsy['RPL_THEMES'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy['Insurance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy['HISPANIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy['RACE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy['RUCA'].value_counts() #RUCA = Rurality for facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy['CCI1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_biopsy['RUCA_Person'].value_counts() #Rurality for personal address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMI_biopsy = first_date_rows1[first_date_rows1['ID'].isin(biopsy_afterID)]\n",
    "BMI_biopsy['BMI_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BMI_biopsy['ORIGINAL_BMI'].mean())\n",
    "print(BMI_biopsy['ORIGINAL_BMI'].median())\n",
    "print(BMI_biopsy['ORIGINAL_BMI'].std())\n",
    "BMI_biopsy['ORIGINAL_BMI'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMI_biopsy['ORIGINAL_BMI'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMI11 = BMI_biopsy[BMI_biopsy['ORIGINAL_BMI']<1000]\n",
    "BMI11['ORIGINAL_BMI'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMI11['ORIGINAL_BMI'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-genome",
   "metadata": {},
   "source": [
    "## For cancer cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic6_cancer = Demographic6[Demographic6['ID'].isin(cancer_afterID)]\n",
    "Demographic6_cancer = Demographic6_18month1[Demographic6_18month1['Cancer_18month']  == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Demographic6_cancer['age'].mean())\n",
    "print(Demographic6_cancer['age'].median())\n",
    "print(Demographic6_cancer['age'].std())\n",
    "Demographic6_cancer['age'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Demographic6_cancer['SVI_Person'].mean())\n",
    "print(Demographic6_cancer['SVI_Person'].median())\n",
    "print(Demographic6_cancer['SVI_Person'].std())\n",
    "Demographic6_cancer['SVI_Person'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_cancer[Demographic6_cancer['SVI_Person'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Demographic6_cancer['RPL_THEMES'].mean())\n",
    "print(Demographic6_cancer['RPL_THEMES'].median())\n",
    "print(Demographic6_cancer['RPL_THEMES'].std())\n",
    "Demographic6_cancer['RPL_THEMES'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_cancer[Demographic6_cancer['RPL_THEMES'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_cancer['Insurance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_cancer['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_cancer['HISPANIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_cancer['RACE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_cancer['RUCA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_cancer['CCI1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demographic6_cancer['RUCA_Person'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMI_biopsy = first_date_rows1[first_date_rows1['ID'].isin(cancer_afterID)]\n",
    "BMI_biopsy['BMI_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BMI_biopsy['ORIGINAL_BMI'].mean())\n",
    "print(BMI_biopsy['ORIGINAL_BMI'].median())\n",
    "print(BMI_biopsy['ORIGINAL_BMI'].std())\n",
    "BMI_biopsy['ORIGINAL_BMI'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMI_biopsy['ORIGINAL_BMI'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-trauma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
